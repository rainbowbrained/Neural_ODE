# Neural_ODE
DL 2025 team project. Reproducible comparison of continuousâ€‘time Neural ODE models against discreteâ€‘time baselines (ResNet, RNN, LSTM) on irregular timeâ€‘series forecasting tasks.


## âœ… Completed Tasks
1. Generated synthetic dataset: A toy linear ODE system.
2. Implemented `ODEFunc` class: simple linear transformation of hidden state.
3. Used `torchdiffeq.odeint` to solve the ODE: predicted state trajectories with initial value problem solver.
4. Training + visualisation


## ğŸ”§ Remaining Tasks
- Implement and train RNN-based models: Compare with standard RNN, GRU, or LSTM architectures on the same task.
- Build and evaluate ODE-RNN model: Fuse ODE solver with RNN encoder as in the Latent ODE architecture.
- Compare performance: Run benchmarks and visualize error metrics vs time steps or noise.
- Use a richer or real-world dataset: e.g. irregular medical time series, financial time series.
- Organize project repository: Create structured GitHub repo with README.md, dataset loaders, training scripts.
- Prepare presentation slides: Explain motivation, theory, models, results, comparison, and conclusions.


| **Member / GitHub handle**            | **Primary Deliverables**          | **Detailed Weekly Tasks & Milestones**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| ------------------------------------- | --------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **@member1 Dmitry â€“ ResNet**     | *Image/sequence ResNet baseline*  | <br>â€¢ Review dataset specs; design ResNet depth/width grid.<br>â€¢ Stub `src/models/resnet.py`, forward pass + unit-test.<br><br>â€¢ Integrate Lightning Module, add early-stopping & LR-scheduler.<br>â€¢ Run first training sweep â†’ baseline metrics on W\&B.<br><br>â€¢ Add configurable bottleneck / dilated blocks; ablation script.<br>â€¢ Deliver inference-latency profiler notebook.<br><br>â€¢ Final tune (â‰¤1 % MSE target); export `resnet.ckpt`, update results table, write Â½-page methods subsection.                      |
| **@member2 Artemiy â€“ RNN (GRU)** | *GRU baseline for irregular Î”t*   | â€¢ Implement `TimeAwareGRU` (Î”t concatenation) in `src/models/rnn.py`.<br>â€¢ Unit-test hidden-state reset & masking.<br> â€¢ Training loop; log N\_par, FLOPs.<br>â€¢ Hyper-opt hidden-units vs seq-length; compare to ResNet.<br> â€¢ Document failure modes & lessons-learned slide.                                                                                                                                                                                                                                             |
| **@member3 Akmuhammed â€“ LSTM**   | *Standard + Time-LSTM baseline*   |â€¢ Fork Artemiyâ€™s dataloader; add `TimeLSTM` variant.<br>  â€¢ Run same sweeps; capture learning-curve SVGs.<br>â€¢ Implement teacher-forcing vs scheduled-sampling toggle.<br> â€¢ Provide extrapolation demo GIF + write comparative paragraph.                                                                                                                                                                                                                                                                                  |
| **@member4 Alina â€“ ODE**         | *Neural ODE / Latent ODE module*  |  â€¢ Fork `torchdiffeq`; wrap `ODEBlock` + adjoint tests.<br> â€¢ Reproduce paperâ€™s spiral demo; log NFE stats.<br> â€¢ Plug into shared trainer; tune solver tolerances vs error.<br>â€¢ Add memory-profiling callback.<br> â€¢ Stretch: continuous normalising-flow or CNF head.<br>â€¢ Prepare â€œODE-internalsâ€ slide & code walkthrough.                                                                                                                                                                                              |
| **Anita â€“ Data & MLOps**         | *Dataset, CI, sweeps, evaluation* | â€¢ Freeze dataset (data-card.md), write `dataloader.py`.<br>â€¢ Set up repo structure, pre-commit, Black/isort, GitHub Actions (lint + unit tests + smoke-train).<br> â€¢ Hydra/YAML config schema; W\&B project; Optuna sweep script.<br>â€¢ Provide `run.sh --model=<name>` wrapper.<br> â€¢ Evaluation notebook: metrics table, paired t-test, NFE curves.<br>â€¢ Collect all checkpoints; generate leaderboard CSV.<br>  â€¢ Assemble final figures, ensure reproducibility (`docker/`), polish README & deliver 10-min Colab demo. |



____________________________________________________________________
# README.MD draft

---

## â­Â Project Highlights

* **â‰¤â€¯1â€¯% error target** (MSE) on chosen dataset
* Unified experiment engine (HydraÂ +Â PyTorch Lightning)
* Endâ€‘toâ€‘end reproducibility: oneâ€‘command run, CI smoke test, W\&B tracking
* Extensible plugâ€‘in interfaceÂ â€” drop your `Model` class, rerun, compare

---

## 1. QuickÂ Start

```bash
# clone
git clone https://github.com/rainbowbrained/Neural_ODE.git
cd Neural_ODE
# example run (NeuralÂ ODE)
python train.py model=ode dataset=physionet
```

*See `configs/` for all options.*

---

## 2. Dataset

| Name               | Domain               | Samples           | Î”t Characteristics | License |
| ------------------ | -------------------- | ----------------- | ------------------ | ------- |
| PhysioNetÂ ICU 2012 | Vital signs (health) | 8â€¯kÂ patients      | Highly irregular   | MIT     |
| Synthetic Spiral   | Toy                  | 10â€¯k trajectories | Uniform            | MIT     |

Download will autoâ€‘trigger on first run and cache under `data/`.

---

## 3. Directory Layout

```
â”œâ”€â”€ data/             # raw & processed datasets
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/       # resnet.py, rnn.py, lstm.py, ode.py
â”‚   â”œâ”€â”€ datamodules/  # pytorchâ€‘lightning data modules
â”‚   â”œâ”€â”€ utils/        # common helpers
â”‚   â””â”€â”€ train.py      # entry point
â”œâ”€â”€ configs/          # Hydra YAML configs
â”œâ”€â”€ sweeps/           # hyperâ€‘parameter search definitions
â”œâ”€â”€ tests/            # unit & integration tests
â”œâ”€â”€ scripts/          # helper bash/nb scripts
â”œâ”€â”€ results/          # artifacts & metrics (autoâ€‘generated)
â”œâ”€â”€ environment.yml   # conda env spec
â””â”€â”€ LICENSE
```

---

## 4. Training & Evaluation

| Model          | Params | TrainÂ NFE | ValÂ MSEÂ â†“ | InferenceÂ latencyÂ (ms) |
| -------------- | ------ | --------- | --------- | ---------------------- |
| ResNetâ€‘18      | 11â€¯M   | Â â€“        |     |                   |
| GRU            | 1.2â€¯M  | Â â€“        |     |                   |
| LSTM           | 1.3â€¯M  | Â â€“        |     |                   |
| **Neuralâ€¯ODE** | 0.8â€¯M  | 57        |     |                   |

*Numbers are placeholders â€“ seeÂ `results.csv` for latest.*

---

## 5. Team & Roles

| Member       | GitHub                | Responsibility                  |
| ------------ | --------------------- | ------------------------------- |
| @member1 Dmitry | ResNet Lead           | Deep residual baseline          |
| @member2 Artemiy | RNN Lead              | GRU baseline                    |
| @member3 Akmuhammed | LSTM Lead             | LSTM baseline                   |
| @member4 Alina | ODE Lead              | Neural ODE module               |
| @rainbowbrained  | DataÂ &Â MLOps  | Dataset, CI, sweeps, evaluation |
